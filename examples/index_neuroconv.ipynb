{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing NeuroCONV Repository\n",
    "\n",
    "This notebook demonstrates how to use repo-indexer to index and search through the [NeuroCONV](https://github.com/catalystneuro/neuroconv) repository, which is a tool for converting neurophysiology data to NWB format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable nested asyncio support for Jupyter notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "You can choose between using OpenAI's embeddings (higher quality, requires API key) or a local model (free, runs locally):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Using OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from repo_indexer.indexer import RepoIndexer\n",
    "from repo_indexer.embeddings import OPENAI_ADA_002\n",
    "\n",
    "# Initialize indexer with OpenAI embeddings\n",
    "indexer = RepoIndexer(\n",
    "    qdrant_url=\"http://localhost:6333\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    collection_name=\"neuroconv\",  # Dedicated collection for neuroconv\n",
    "    embedding_model=OPENAI_ADA_002\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Using Local E5 Model\n",
    "\n",
    "This option requires running the local embedding server. First, start the server with:\n",
    "```bash\n",
    "docker run -p 8001:80 ghcr.io/huggingface/text-embeddings-inference:cpu-0.3 --model-id intfloat/multilingual-e5-small\n",
    "```\n",
    "\n",
    "The server will be available at http://localhost:8001. You can customize this in two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repo_indexer.indexer import RepoIndexer\n",
    "from repo_indexer.embeddings import LocalE5Embeddings\n",
    "\n",
    "# Create custom embedding generator with specific URL\n",
    "embedding_generator = LocalE5Embeddings(\n",
    "    url=\"http://localhost:8001/v1/embeddings\"\n",
    ")\n",
    "\n",
    "# Initialize indexer with custom generator\n",
    "indexer = RepoIndexer(\n",
    "    qdrant_url=\"http://localhost:6333\",\n",
    "    collection_name=\"neuroconv\",\n",
    "    embedding_generator=embedding_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repository Processing\n",
    "\n",
    "Let's process the repository step by step, focusing on Python files to understand the core functionality:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Parse Repository\n",
    "\n",
    "First, we parse the repository to get its raw content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the repository\n",
    "repo_url = \"https://github.com/catalystneuro/neuroconv.git\"\n",
    "indexer.parse_repo(repo_url)\n",
    "\n",
    "# Access stored metadata\n",
    "repo_data = indexer.repositories[repo_url]\n",
    "\n",
    "print(\"\\nRepository Summary:\")\n",
    "print(repo_data[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRepository Tree:\")\n",
    "print(repo_data[\"tree\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(repo_data[\"content\"][240][0])\n",
    "print(repo_data[\"content\"][240][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate Chunks\n",
    "\n",
    "Next, we split the content into meaningful chunks, focusing on Python files and setting reasonable token limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate chunks from Python files\n",
    "indexer.generate_chunks(\n",
    "    repo_url=repo_url,\n",
    "    min_tokens=20,     # Skip very small chunks\n",
    "    # max_tokens=5000,    # Limit chunk size for better context\n",
    "    file_types=[\".py\"] # Only process Python files\n",
    ")\n",
    "\n",
    "chunks = indexer.repositories[repo_url][\"chunks\"]\n",
    "print(f\"Generated {len(chunks)} chunks from Python files\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate Embeddings\n",
    "\n",
    "Now we generate embeddings for each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "indexer.generate_embeddings(repo_url)\n",
    "\n",
    "# Get a sample chunk with its embedding\n",
    "sample_chunk = chunks[0]\n",
    "print(f\"Generated embeddings for {len(chunks)} chunks\")\n",
    "print(f\"Vector size: {len(sample_chunk.embedding)}\")\n",
    "\n",
    "print(\"\\nSample chunk:\")\n",
    "print(f\"Content: {sample_chunk.content[:100]}...\")\n",
    "print(\"\\nIts embedding vector (first 10 dimensions):\")\n",
    "print(sample_chunk.embedding[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Store in Vector Database\n",
    "\n",
    "Finally, we store the chunks and their embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store chunks and embeddings\n",
    "indexer.insert_chunks(repo_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: One-Step Processing\n",
    "\n",
    "If you don't need to examine the intermediate results, you can use the convenience method that runs all steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process everything in one step, still focusing on Python files\n",
    "indexer.index_repository(\n",
    "    repo_url=\"https://github.com/catalystneuro/neuroconv.git\",\n",
    "    min_tokens=50,\n",
    "    max_tokens=500,\n",
    "    file_types=[\".py\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Examples\n",
    "\n",
    "Let's try some searches focused on different aspects of NeuroCONV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    \"\"\"Helper to print search results nicely.\"\"\"\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\nResult {i} (Score: {result['score']:.3f})\")\n",
    "        print(f\"File: {result['file']}\")\n",
    "        if result['lines'][0]:\n",
    "            print(f\"Lines: {result['lines'][0]}-{result['lines'][1]}\")\n",
    "        print(\"Content:\")\n",
    "        print(result['content'])\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Find Data Conversion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for data conversion functionality\n",
    "results = indexer.search(\n",
    "    query=\"function to convert data to NWB format\",\n",
    "    limit=3,\n",
    "    chunk_type=\"code\"\n",
    ")\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Find Interface Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for interface documentation\n",
    "results = indexer.search(\n",
    "    query=\"interface documentation for converting neurophysiology data\",\n",
    "    limit=3,\n",
    "    chunk_type=\"documentation\"\n",
    ")\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find Configuration Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for configuration examples\n",
    "results = indexer.search(\n",
    "    query=\"configuration settings for data conversion\",\n",
    "    limit=3,\n",
    "    chunk_type=\"configuration\"\n",
    ")\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Find Test Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for test examples\n",
    "results = indexer.search(\n",
    "    query=\"test cases for data conversion\",\n",
    "    limit=3,\n",
    "    file_extension=\"py\",  # Look in Python files\n",
    "    chunk_type=\"code\"\n",
    ")\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Find Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for error handling code\n",
    "results = indexer.search(\n",
    "    query=\"error handling during data conversion\",\n",
    "    limit=3,\n",
    "    chunk_type=\"code\"\n",
    ")\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "If you want to remove the indexed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repo_indexer.clients import QdrantManager\n",
    "\n",
    "# Initialize manager\n",
    "manager = QdrantManager(url=\"http://localhost:6333\")\n",
    "\n",
    "# Delete the collection\n",
    "manager.delete_collection(\"neuroconv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_llm",
   "language": "python",
   "name": "env_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
